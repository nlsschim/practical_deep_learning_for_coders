{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import fastai\n",
    "import azureml\n",
    "import azureml.core\n",
    "from azureml.core import Dataset, Run, Datastore, Workspace\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from diff_classifier import features\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for local debugging\n",
    "subscription_id = '9c49afdd-cccb-44e2-a4eb-5b2f941c774c'\n",
    "resource_group = 'schimek_cloud'\n",
    "workspace_name = 'nels_east_us'\n",
    "\n",
    "workspace = azureml.core.Workspace(subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = Datastore.get(workspace, 'workspaceblobstore')\n",
    "file_dataset = Dataset.File.from_files(path=(datastore, 'UI/2023-04-21_000140_UTC/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = file_dataset.register(workspace = workspace, name = 'mpt_training_data', create_new_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/batch/tasks/shared/LS_root/mounts/clusters/nlsschim1/code/Users/nlsschim/practical_deep_learning_for_coders/notebooks/msd_P14_40nm_s1_v1.csv',\n",
       " '/mnt/batch/tasks/shared/LS_root/mounts/clusters/nlsschim1/code/Users/nlsschim/practical_deep_learning_for_coders/notebooks/msd_P14_40nm_s1_v2.csv',\n",
       " '/mnt/batch/tasks/shared/LS_root/mounts/clusters/nlsschim1/code/Users/nlsschim/practical_deep_learning_for_coders/notebooks/msd_P14_40nm_s1_v3.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.get_by_name(workspace, name='mpt_training_data')\n",
    "dataset.download(target_path='.', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Frame</th>\n",
       "      <th>Track_ID</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>MSDs</th>\n",
       "      <th>Gauss</th>\n",
       "      <th>Quality</th>\n",
       "      <th>SN_Ratio</th>\n",
       "      <th>Mean_Intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>221.940562</td>\n",
       "      <td>0.945131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>395.453323</td>\n",
       "      <td>0.604359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>530.226501</td>\n",
       "      <td>0.588696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>627.000852</td>\n",
       "      <td>0.457320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Frame  Track_ID   X   Y        MSDs     Gauss  Quality   \n",
       "0           0    0.0       0.0 NaN NaN    0.000000  0.000000      NaN  \\\n",
       "1           1    1.0       0.0 NaN NaN  221.940562  0.945131      NaN   \n",
       "2           2    2.0       0.0 NaN NaN  395.453323  0.604359      NaN   \n",
       "3           3    3.0       0.0 NaN NaN  530.226501  0.588696      NaN   \n",
       "4           4    4.0       0.0 NaN NaN  627.000852  0.457320      NaN   \n",
       "\n",
       "   SN_Ratio  Mean_Intensity  \n",
       "0       NaN             NaN  \n",
       "1       NaN             NaN  \n",
       "2       NaN             NaN  \n",
       "3       NaN             NaN  \n",
       "4       NaN             NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.read_csv('msd_p14_40nm_s1_v1.csv')\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_dataset(csv, track_id_col, output_dir):\n",
    "\n",
    "    labels = {}\n",
    "    track_ids = []\n",
    "    file_name = csv\n",
    "    df = pd.read_csv(csv)\n",
    "    for track_id in df[track_id_col].unique():\n",
    "        label = file_name[:-4] + f'_track_{int(track_id)}.npy'\n",
    "        comp_track = features.unmask_track(df[df['Track_ID']==track_id])\n",
    "        if len(comp_track['X']) >= 10:\n",
    "            alpha, dcoef = features.alpha_calc(comp_track)\n",
    "            if dcoef > 0 and dcoef < 20:\n",
    "                track_data = comp_track[['X', 'Y']]\n",
    "                labels[str(label)] = dcoef\n",
    "                track_ids.append(str(label))\n",
    "                test_array = np.array(track_data)\n",
    "                new_shape = (651, 2)\n",
    "                pad_width = [(0, new_shape[i] - test_array.shape[i]) for i in range(len(new_shape))]\n",
    "                out_array = np.pad(test_array, pad_width, mode='constant')\n",
    "                #np.save(output_dir + str(label), out_array)\n",
    "    labels = pd.DataFrame.from_dict(labels, orient='index', columns=['dcoef'])\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = make_new_dataset('msd_p14_40nm_s1_v1.csv', 'Track_ID', 'training_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.to_csv('training_data/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msd_p14_40nm_s1_v1_track_1.npy\n",
      "1.6117280148626445\n"
     ]
    }
   ],
   "source": [
    "traj_labels = pd.read_csv('training_data/labels.csv')\n",
    "print(traj_labels.iloc[0, 0])\n",
    "print(traj_labels.iloc[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MptDataset(Dataset):\n",
    "    def __init__(self, annotations_file, traj_dir, transform=None, target_transform=None):\n",
    "        self.traj_labels = pd.read_csv(annotations_file)\n",
    "        self.traj_dir = traj_dir\n",
    "        self.transform = transform # for future use maybe?\n",
    "        self.target_transform = target_transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.traj_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        traj_path = os.path.join(self.traj_dir, self.traj_labels.iloc[idx, 0])\n",
    "        traj = np.load(traj_path)\n",
    "        label = self.traj_labels.iloc[idx, 1]\n",
    "       \n",
    "        return traj, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(MptDataset('training_data/labels.csv', 'training_data/'), batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 651, 2])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([14.,  6.,  8.,  1.,  5.,  7.,  5.,  4.,  8.,  6.]),\n",
       " array([7.44710107e-07, 1.94879044e+00, 3.89758013e+00, 5.84636982e+00,\n",
       "        7.79515951e+00, 9.74394920e+00, 1.16927389e+01, 1.36415286e+01,\n",
       "        1.55903183e+01, 1.75391080e+01, 1.94878977e+01]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAeW0lEQVR4nO3de3CV9Z348U/kEpAlQbAQsiZAnVZaRKpWGXQvWjNiliJ0u/UyrKW0q73EWkq3C9lZpIzbRtuOw9YyaDtV7LReZwS7uquDlEsvoEJwV7tdCt2IaTGw7S4JlxKY5Nk/fj/ONJAEQk/4JofXa+bMcJ7zPc/zffie43l7csIpyrIsCwCARM5JPQEA4OwmRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAIKmBqSdwvPb29ti9e3cMHz48ioqKUk8HADgFWZbF/v37o7y8PM45p2fvdfS5GNm9e3dUVFSkngYAcBoaGxvjggsu6NF9+lyMDB8+PCL+38mUlJQkng0AcCpaWlqioqIi9zreE30uRo79aKakpESMAEA/czofsfABVgAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAk1eMY2bhxY8ycOTPKy8ujqKgoVq9e3eXYT33qU1FUVBTLli37A6YIABSyHsfIwYMHY8qUKbF8+fJux61atSo2b94c5eXlpz05AKDw9fiL8qqrq6O6urrbMb/+9a/js5/9bLz44osxY8aM054cAFD48v6tve3t7XHbbbfFF7/4xZg0adJJx7e2tkZra2vuektLS76nBAD0YXmPkfvuuy8GDhwYd9111ymNr6uri6VLl+Z7Gl0av+j5M3asfHnzXu8uAVC48vrbNFu3bo1/+qd/ipUrV0ZRUdEp3ae2tjaam5tzl8bGxnxOCQDo4/IaIz/60Y9i7969UVlZGQMHDoyBAwfGrl274gtf+EKMHz++0/sUFxdHSUlJhwsAcPbI649pbrvttqiqquqwbfr06XHbbbfFvHnz8nkoAKBA9DhGDhw4EDt37sxdb2hoiNdeey1GjhwZlZWVMWrUqA7jBw0aFGVlZXHRRRf94bMFAApOj2Nky5Ytce211+auL1iwICIi5s6dGytXrszbxACAs0OPY+Saa66JLMtOefybb77Z00MAAGcR300DACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASfU4RjZu3BgzZ86M8vLyKCoqitWrV+duO3r0aCxcuDAmT54cw4YNi/Ly8vjoRz8au3fvzuecAYAC0uMYOXjwYEyZMiWWL19+wm2HDh2K+vr6WLx4cdTX18czzzwT27dvjxtvvDEvkwUACs/Ant6huro6qqurO72ttLQ01qxZ02HbN7/5zbjyyivjrbfeisrKytObJQBQsHr9MyPNzc1RVFQUI0aM6O1DAQD9UI/fGemJw4cPx8KFC+PWW2+NkpKSTse0trZGa2tr7npLS0tvTgkA6GN67Z2Ro0ePxk033RRZlsWKFSu6HFdXVxelpaW5S0VFRW9NCQDog3olRo6FyK5du2LNmjVdvisSEVFbWxvNzc25S2NjY29MCQDoo/L+Y5pjIbJjx45Yt25djBo1qtvxxcXFUVxcnO9pAAD9RI9j5MCBA7Fz587c9YaGhnjttddi5MiRMXbs2Pirv/qrqK+vj+eeey7a2tqiqakpIiJGjhwZgwcPzt/MAYCC0OMY2bJlS1x77bW56wsWLIiIiLlz58aXvvSl+MEPfhAREe973/s63G/dunVxzTXXnP5MAYCC1OMYueaaayLLsi5v7+42AIDj+W4aACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJ9ThGNm7cGDNnzozy8vIoKiqK1atXd7g9y7K4++67Y+zYsTF06NCoqqqKHTt25Gu+AECB6XGMHDx4MKZMmRLLly/v9PavfvWr8Y1vfCMefPDBePnll2PYsGExffr0OHz48B88WQCg8Azs6R2qq6ujurq609uyLItly5bFP/zDP8SsWbMiIuK73/1ujBkzJlavXh233HLLHzZbAKDg5PUzIw0NDdHU1BRVVVW5baWlpTF16tTYtGlTp/dpbW2NlpaWDhcA4OyR1xhpamqKiIgxY8Z02D5mzJjcbcerq6uL0tLS3KWioiKfUwIA+rjkv01TW1sbzc3NuUtjY2PqKQEAZ1BeY6SsrCwiIvbs2dNh+549e3K3Ha+4uDhKSko6XACAs0deY2TChAlRVlYWa9euzW1raWmJl19+OaZNm5bPQwEABaLHv01z4MCB2LlzZ+56Q0NDvPbaazFy5MiorKyM+fPnxz/+4z/Gu971rpgwYUIsXrw4ysvLY/bs2fmcNwBQIHocI1u2bIlrr702d33BggURETF37txYuXJl/N3f/V0cPHgw7rjjjti3b1/8yZ/8SbzwwgsxZMiQ/M0aACgYRVmWZakn8ftaWlqitLQ0mpube+XzI+MXPZ/3ffa2N++dkXoKANCtP+T1O/lv0wAAZzcxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABIKu8x0tbWFosXL44JEybE0KFD48ILL4x77rknsizL96EAgAIwMN87vO+++2LFihXx6KOPxqRJk2LLli0xb968KC0tjbvuuivfhwMA+rm8x8hPf/rTmDVrVsyYMSMiIsaPHx+PP/54vPLKK/k+FABQAPL+Y5qrrroq1q5dG7/4xS8iIuLf/u3f4sc//nFUV1d3Or61tTVaWlo6XACAs0fe3xlZtGhRtLS0xMSJE2PAgAHR1tYWX/7yl2POnDmdjq+rq4ulS5fmexokNn7R86mn0GNv3jsj9RTgrOe/HWenvL8z8tRTT8X3v//9eOyxx6K+vj4effTR+PrXvx6PPvpop+Nra2ujubk5d2lsbMz3lACAPizv74x88YtfjEWLFsUtt9wSERGTJ0+OXbt2RV1dXcydO/eE8cXFxVFcXJzvaQAA/UTe3xk5dOhQnHNOx90OGDAg2tvb830oAKAA5P2dkZkzZ8aXv/zlqKysjEmTJsW2bdvi/vvvj49//OP5PhQAUADyHiMPPPBALF68OD7zmc/E3r17o7y8PD75yU/G3Xffne9DAQAFIO8xMnz48Fi2bFksW7Ys37sGAAqQ76YBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSA1NPADi7jF/0fOop9Nib985IPQUoaN4ZAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASfVKjPz617+Ov/7rv45Ro0bF0KFDY/LkybFly5beOBQA0M8NzPcO//d//zeuvvrquPbaa+Nf//Vf4x3veEfs2LEjzjvvvHwfCgAoAHmPkfvuuy8qKirikUceyW2bMGFCvg8DABSIvP+Y5gc/+EG8//3vj4985CMxevTouPTSS+Pb3/52l+NbW1ujpaWlwwUAOHvk/Z2R//qv/4oVK1bEggUL4u///u/j1VdfjbvuuisGDx4cc+fOPWF8XV1dLF26NN/TKCjjFz2fegoAdKE//jf6zXtnpJ5CB3l/Z6S9vT0uu+yy+MpXvhKXXnpp3HHHHXH77bfHgw8+2On42traaG5uzl0aGxvzPSUAoA/Le4yMHTs23vve93bY9p73vCfeeuutTscXFxdHSUlJhwsAcPbIe4xcffXVsX379g7bfvGLX8S4cePyfSgAoADkPUY+//nPx+bNm+MrX/lK7Ny5Mx577LH41re+FTU1Nfk+FABQAPIeI1dccUWsWrUqHn/88bj44ovjnnvuiWXLlsWcOXPyfSgAoADk/bdpIiI++MEPxgc/+MHe2DUAUGB8Nw0AkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUgNTTwA4feMXPZ96CmeF/vr3/Oa9M1JPAU6Jd0YAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSvR4j9957bxQVFcX8+fN7+1AAQD/UqzHy6quvxkMPPRSXXHJJbx4GAOjHei1GDhw4EHPmzIlvf/vbcd555/XWYQCAfq7XYqSmpiZmzJgRVVVV3Y5rbW2NlpaWDhcA4OwxsDd2+sQTT0R9fX28+uqrJx1bV1cXS5cu7Y1pAJzVxi96PvUU4JTk/Z2RxsbG+NznPhff//73Y8iQIScdX1tbG83NzblLY2NjvqcEAPRheX9nZOvWrbF379647LLLctva2tpi48aN8c1vfjNaW1tjwIABuduKi4ujuLg439MAAPqJvMfIddddF6+//nqHbfPmzYuJEyfGwoULO4QIAEDeY2T48OFx8cUXd9g2bNiwGDVq1AnbAQD8C6wAQFK98ts0x1u/fv2ZOAwA0A95ZwQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSynuM1NXVxRVXXBHDhw+P0aNHx+zZs2P79u35PgwAUCDyHiMbNmyImpqa2Lx5c6xZsyaOHj0a119/fRw8eDDfhwIACsDAfO/whRde6HB95cqVMXr06Ni6dWv82Z/9Wb4PBwD0c3mPkeM1NzdHRMTIkSM7vb21tTVaW1tz11taWnp7SgBAH9KrH2Btb2+P+fPnx9VXXx0XX3xxp2Pq6uqitLQ0d6moqOjNKQEAfUyvxkhNTU288cYb8cQTT3Q5pra2Npqbm3OXxsbG3pwSANDH9NqPae6888547rnnYuPGjXHBBRd0Oa64uDiKi4t7axoAQB+X9xjJsiw++9nPxqpVq2L9+vUxYcKEfB8CACggeY+RmpqaeOyxx+LZZ5+N4cOHR1NTU0RElJaWxtChQ/N9OACgn8v7Z0ZWrFgRzc3Ncc0118TYsWNzlyeffDLfhwIACkCv/JgGAOBU+W4aACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkNTD1BKCvGL/o+dRTADgreWcEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAk1Wsxsnz58hg/fnwMGTIkpk6dGq+88kpvHQoA6Md6JUaefPLJWLBgQSxZsiTq6+tjypQpMX369Ni7d29vHA4A6Md6JUbuv//+uP3222PevHnx3ve+Nx588ME499xz4+GHH+6NwwEA/djAfO/wyJEjsXXr1qitrc1tO+ecc6Kqqio2bdp0wvjW1tZobW3NXW9ubo6IiJaWlnxPLSIi2lsP9cp+AaC/6I3X2GP7zLKsx/fNe4z85je/iba2thgzZkyH7WPGjIn//M//PGF8XV1dLF269ITtFRUV+Z4aABARpct6b9/79++P0tLSHt0n7zHSU7W1tbFgwYLc9fb29vif//mfGDVqVBQVFeX1WC0tLVFRURGNjY1RUlKS1333Jc6zcJwN5xjhPAuN8ywsp3qeWZbF/v37o7y8vMfHyHuMnH/++TFgwIDYs2dPh+179uyJsrKyE8YXFxdHcXFxh20jRozI97Q6KCkpKegHzjHOs3CcDecY4TwLjfMsLKdynj19R+SYvH+AdfDgwXH55ZfH2rVrc9va29tj7dq1MW3atHwfDgDo53rlxzQLFiyIuXPnxvvf//648sorY9myZXHw4MGYN29ebxwOAOjHeiVGbr755vjv//7vuPvuu6OpqSne9773xQsvvHDCh1rPtOLi4liyZMkJPxYqNM6zcJwN5xjhPAuN8ywsZ+I8i7LT+R0cAIA88d00AEBSYgQASEqMAABJiREAIKmCi5Hly5fH+PHjY8iQITF16tR45ZVXuh3/9NNPx8SJE2PIkCExefLk+Jd/+ZczNNPTU1dXF1dccUUMHz48Ro8eHbNnz47t27d3e5+VK1dGUVFRh8uQIUPO0IxPz5e+9KUT5jxx4sRu79Pf1jIiYvz48SecZ1FRUdTU1HQ6vj+s5caNG2PmzJlRXl4eRUVFsXr16g63Z1kWd999d4wdOzaGDh0aVVVVsWPHjpPut6fP7d7W3XkePXo0Fi5cGJMnT45hw4ZFeXl5fPSjH43du3d3u8/Tedz3tpOt58c+9rET5nzDDTecdL/9aT0jotPnaVFRUXzta1/rcp99bT1P5fXj8OHDUVNTE6NGjYo/+qM/ig9/+MMn/COmxzvd5/TvK6gYefLJJ2PBggWxZMmSqK+vjylTpsT06dNj7969nY7/6U9/Grfeemt84hOfiG3btsXs2bNj9uzZ8cYbb5zhmZ+6DRs2RE1NTWzevDnWrFkTR48ejeuvvz4OHjzY7f1KSkri7bffzl127dp1hmZ8+iZNmtRhzj/+8Y+7HNsf1zIi4tVXX+1wjmvWrImIiI985CNd3qevr+XBgwdjypQpsXz58k5v/+pXvxrf+MY34sEHH4yXX345hg0bFtOnT4/Dhw93uc+ePrfPhO7O89ChQ1FfXx+LFy+O+vr6eOaZZ2L79u1x4403nnS/PXncnwknW8+IiBtuuKHDnB9//PFu99nf1jMiOpzf22+/HQ8//HAUFRXFhz/84W7325fW81RePz7/+c/HP//zP8fTTz8dGzZsiN27d8df/uVfdrvf03lOnyArIFdeeWVWU1OTu97W1paVl5dndXV1nY6/6aabshkzZnTYNnXq1OyTn/xkr84zn/bu3ZtFRLZhw4YuxzzyyCNZaWnpmZtUHixZsiSbMmXKKY8vhLXMsiz73Oc+l1144YVZe3t7p7f3t7WMiGzVqlW56+3t7VlZWVn2ta99Lbdt3759WXFxcfb44493uZ+ePrfPtOPPszOvvPJKFhHZrl27uhzT08f9mdbZec6dOzebNWtWj/ZTCOs5a9as7AMf+EC3Y/r6eh7/+rFv375s0KBB2dNPP50b8/Of/zyLiGzTpk2d7uN0n9PHK5h3Ro4cORJbt26Nqqqq3LZzzjknqqqqYtOmTZ3eZ9OmTR3GR0RMnz69y/F9UXNzc0REjBw5sttxBw4ciHHjxkVFRUXMmjUrfvazn52J6f1BduzYEeXl5fHOd74z5syZE2+99VaXYwthLY8cORLf+9734uMf/3i3XxLZH9fymIaGhmhqauqwVqWlpTF16tQu1+p0ntt9UXNzcxQVFZ30u7d68rjvK9avXx+jR4+Oiy66KD796U/Hb3/72y7HFsJ67tmzJ55//vn4xCc+cdKxfXk9j3/92Lp1axw9erTD2kycODEqKyu7XJvTeU53pmBi5De/+U20tbWd8K+8jhkzJpqamjq9T1NTU4/G9zXt7e0xf/78uPrqq+Piiy/uctxFF10UDz/8cDz77LPxve99L9rb2+Oqq66KX/3qV2dwtj0zderUWLlyZbzwwguxYsWKaGhoiD/90z+N/fv3dzq+v69lRMTq1atj37598bGPfazLMf1xLX/fsfXoyVqdznO7rzl8+HAsXLgwbr311m6/aKynj/u+4IYbbojvfve7sXbt2rjvvvtiw4YNUV1dHW1tbZ2OL4T1fPTRR2P48OEn/fFFX17Pzl4/mpqaYvDgwScE88leR4+NOdX7dKZX/jl4zoyampp44403TvozyGnTpnX4ksKrrroq3vOe98RDDz0U99xzT29P87RUV1fn/nzJJZfE1KlTY9y4cfHUU0+d0v+N9Eff+c53orq6utuv3+6Pa3m2O3r0aNx0002RZVmsWLGi27H98XF/yy235P48efLkuOSSS+LCCy+M9evXx3XXXZdwZr3n4Ycfjjlz5pz0w+N9eT1P9fXjTCmYd0bOP//8GDBgwAmf+t2zZ0+UlZV1ep+ysrIeje9L7rzzznjuuedi3bp1ccEFF/TovoMGDYpLL700du7c2Uuzy78RI0bEu9/97i7n3J/XMiJi165d8dJLL8Xf/M3f9Oh+/W0tj61HT9bqdJ7bfcWxENm1a1esWbOmx18zf7LHfV/0zne+M84///wu59yf1zMi4kc/+lFs3769x8/ViL6znl29fpSVlcWRI0di3759Hcaf7HX02JhTvU9nCiZGBg8eHJdffnmsXbs2t629vT3Wrl3b4f8kf9+0adM6jI+IWLNmTZfj+4Isy+LOO++MVatWxQ9/+MOYMGFCj/fR1tYWr7/+eowdO7YXZtg7Dhw4EL/85S+7nHN/XMvf98gjj8To0aNjxowZPbpff1vLCRMmRFlZWYe1amlpiZdffrnLtTqd53ZfcCxEduzYES+99FKMGjWqx/s42eO+L/rVr34Vv/3tb7ucc39dz2O+853vxOWXXx5Tpkzp8X1Tr+fJXj8uv/zyGDRoUIe12b59e7z11ltdrs3pPKe7mlzBeOKJJ7Li4uJs5cqV2X/8x39kd9xxRzZixIisqakpy7Isu+2227JFixblxv/kJz/JBg4cmH3961/Pfv7zn2dLlizJBg0alL3++uupTuGkPv3pT2elpaXZ+vXrs7fffjt3OXToUG7M8ee5dOnS7MUXX8x++ctfZlu3bs1uueWWbMiQIdnPfvazFKdwSr7whS9k69evzxoaGrKf/OQnWVVVVXb++edne/fuzbKsMNbymLa2tqyysjJbuHDhCbf1x7Xcv39/tm3btmzbtm1ZRGT3339/tm3bttxvkdx7773ZiBEjsmeffTb793//92zWrFnZhAkTst/97ne5fXzgAx/IHnjggdz1kz23U+juPI8cOZLdeOON2QUXXJC99tprHZ6rra2tuX0cf54ne9yn0N157t+/P/vbv/3bbNOmTVlDQ0P20ksvZZdddln2rne9Kzt8+HBuH/19PY9pbm7Ozj333GzFihWd7qOvr+epvH586lOfyiorK7Mf/vCH2ZYtW7Jp06Zl06ZN67Cfiy66KHvmmWdy10/lOX0yBRUjWZZlDzzwQFZZWZkNHjw4u/LKK7PNmzfnbvvzP//zbO7cuR3GP/XUU9m73/3ubPDgwdmkSZOy559//gzPuGciotPLI488khtz/HnOnz8/93cyZsyY7C/+4i+y+vr6Mz/5Hrj55puzsWPHZoMHD87++I//OLv55puznTt35m4vhLU85sUXX8wiItu+ffsJt/XHtVy3bl2nj9Fj59He3p4tXrw4GzNmTFZcXJxdd911J5z7uHHjsiVLlnTY1t1zO4XuzrOhoaHL5+q6dety+zj+PE/2uE+hu/M8dOhQdv3112fveMc7skGDBmXjxo3Lbr/99hOior+v5zEPPfRQNnTo0Gzfvn2d7qOvr+epvH787ne/yz7zmc9k5513XnbuuedmH/rQh7K33377hP38/n1O5Tl9MkX/f8cAAEkUzGdGAID+SYwAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAk9X9Ca+miZsRXggAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (conv1): Conv1d(2, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
      "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc1): Linear(in_features=32, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "batch_size = 8\n",
    "T = [50, 51]\n",
    "steps = 1000\n",
    "initializer = nn.init.kaiming_normal_\n",
    "f = 32\n",
    "sigma = 0.1\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(2, f, kernel_size=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(f)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc1 = nn.Linear(f, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.double() # convert input tensor to double precision\n",
    "        x = x.permute(0, 2, 1) # transpose input tensor to shape (batch_size, num_channels, seq_length)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, f)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE:  85.96506982708367\n",
      "Validation MSE:  87.95207896397748\n",
      "Validation MSE:  78.85719818566828\n",
      "Validation MSE:  82.6691163122269\n",
      "Validation MSE:  86.5439929280589\n",
      "Validation MSE:  75.72652240371552\n",
      "Validation MSE:  79.86037870453869\n",
      "Validation MSE:  84.92673266116365\n",
      "Validation MSE:  82.33811533756857\n",
      "Validation MSE:  87.67294022459212\n",
      "Validation MSE:  75.9464778895719\n",
      "Validation MSE:  75.58248238023815\n",
      "Validation MSE:  76.21505287109056\n",
      "Validation MSE:  82.72805426497948\n",
      "Validation MSE:  78.62132392016582\n",
      "Validation MSE:  88.52145274411497\n",
      "Validation MSE:  85.53799822985188\n",
      "Validation MSE:  81.01623624959133\n",
      "Validation MSE:  85.85235280305955\n",
      "Validation MSE:  85.86733935394682\n",
      "Validation MSE:  81.49779215490237\n",
      "Validation MSE:  81.29868251661412\n",
      "Validation MSE:  90.69033956870665\n",
      "Validation MSE:  74.85567532291583\n",
      "Validation MSE:  86.88352931322827\n",
      "Validation MSE:  82.67492520950235\n",
      "Validation MSE:  77.71093941578333\n",
      "Validation MSE:  86.84041418011185\n",
      "Validation MSE:  82.93622160557216\n",
      "Validation MSE:  78.93080572031978\n",
      "Validation MSE:  81.70171645981225\n",
      "Validation MSE:  79.30363031919265\n",
      "Validation MSE:  83.93743772180154\n",
      "Validation MSE:  82.07266190216798\n",
      "Validation MSE:  83.32014288209348\n",
      "Validation MSE:  79.17110422011126\n",
      "Validation MSE:  86.47592416613544\n",
      "Validation MSE:  83.02998416295777\n",
      "Validation MSE:  87.41107259824857\n",
      "Validation MSE:  80.80884354789366\n",
      "Validation MSE:  82.41280118295533\n",
      "Validation MSE:  81.06380132117609\n",
      "Validation MSE:  77.77593831292366\n",
      "Validation MSE:  83.48786463641046\n",
      "Validation MSE:  85.35343182815559\n",
      "Validation MSE:  83.92890640574147\n",
      "Validation MSE:  81.928483490704\n",
      "Validation MSE:  83.84539074699676\n",
      "Validation MSE:  84.04540199142136\n",
      "Validation MSE:  87.39201264982164\n",
      "Validation MSE:  82.0010937571971\n",
      "Validation MSE:  87.66281447641369\n",
      "Validation MSE:  80.14869648375613\n",
      "Validation MSE:  87.205498052761\n",
      "Validation MSE:  83.50288328238189\n",
      "Validation MSE:  84.31286669226841\n",
      "Validation MSE:  84.58772065641\n",
      "Validation MSE:  79.84205097318811\n",
      "Validation MSE:  83.64779300913233\n",
      "Validation MSE:  80.41962116067394\n",
      "Validation MSE:  83.38210218970026\n",
      "Validation MSE:  78.16543688138015\n",
      "Validation MSE:  82.9935547165594\n",
      "Validation MSE:  77.89983176578114\n",
      "Validation MSE:  80.3376669880983\n",
      "Validation MSE:  81.04268258083077\n",
      "Validation MSE:  81.43449851660385\n",
      "Validation MSE:  80.05858819570832\n",
      "Validation MSE:  85.59511984396097\n",
      "Validation MSE:  78.35444276807043\n",
      "Validation MSE:  81.07744004279202\n",
      "Validation MSE:  80.53496662683017\n",
      "Validation MSE:  77.67660382970264\n",
      "Validation MSE:  86.09215367725754\n",
      "Validation MSE:  81.00710183778266\n",
      "Validation MSE:  83.28913885716118\n",
      "Validation MSE:  85.07588710562946\n",
      "Validation MSE:  75.19897246793396\n",
      "Validation MSE:  86.79597604456886\n",
      "Validation MSE:  79.11845473896902\n",
      "Validation MSE:  85.88767715243178\n",
      "Validation MSE:  84.03765685308973\n",
      "Validation MSE:  82.02501662784611\n",
      "Validation MSE:  79.83528652883244\n",
      "Validation MSE:  83.52797734058741\n",
      "Validation MSE:  83.57322699710461\n",
      "Validation MSE:  78.00581253013097\n",
      "Validation MSE:  88.7241722115931\n",
      "Validation MSE:  88.79488183253896\n",
      "Validation MSE:  80.2537022901551\n",
      "Validation MSE:  82.3589223605828\n",
      "Validation MSE:  76.84766687308826\n",
      "Validation MSE:  83.24935507141767\n",
      "Validation MSE:  89.59913945759513\n",
      "Validation MSE:  89.94943528524334\n",
      "Validation MSE:  81.19200273622427\n",
      "Validation MSE:  81.38060866550151\n",
      "Validation MSE:  80.04803113177623\n",
      "Validation MSE:  80.18642450916893\n",
      "Validation MSE:  89.28049249827724\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "model = model.double() # convert model to double precision\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.double() # convert inputs to double precision\n",
    "        labels = labels.double() # convert labels to double precision\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "\n",
    "           # Reshape the target tensor if necessary\n",
    "        if labels.shape != outputs.shape:\n",
    "            labels = labels.view(-1, 1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Calculate the MSE for the validation set\n",
    "    val_loss = 0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs = inputs.double() # convert inputs to double precision\n",
    "        labels = labels.double() # convert labels to double precision\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Reshape the target tensor if necessary\n",
    "        if labels.shape != outputs.shape:\n",
    "            labels = labels.view(-1, 1)\n",
    "        loss = F.mse_loss(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "    # Calculate the average MSE for the validation set\n",
    "    avg_val_loss = val_loss / len(train_dataloader)\n",
    "    print(\"Validation MSE: \", avg_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [[1.        ]\n",
      " [1.        ]\n",
      " [0.99999999]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999975]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999989]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999396]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999993]\n",
      " [0.99999996]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999893]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999993 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99995437]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999975]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999999]\n",
      " [0.99757539]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99998633]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999957]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99997614]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999924]\n",
      " [0.99999999]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999999]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999646]\n",
      " [1.        ]\n",
      " [0.9999997 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999993]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99915364]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99916229]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999996]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]]\n",
      "Targets:  [[1.94775354e+00]\n",
      " [8.69458434e+00]\n",
      " [1.70003032e+01]\n",
      " [9.39346409e-01]\n",
      " [1.49186612e+01]\n",
      " [6.80948469e+00]\n",
      " [7.38660017e-01]\n",
      " [7.89299507e+00]\n",
      " [5.68802755e+00]\n",
      " [1.94274789e+01]\n",
      " [1.78711356e+01]\n",
      " [1.36610470e+01]\n",
      " [1.20983951e-02]\n",
      " [9.29183845e+00]\n",
      " [1.47335102e+01]\n",
      " [5.24223961e-01]\n",
      " [4.74843842e-01]\n",
      " [3.67256713e+00]\n",
      " [1.61105200e+00]\n",
      " [6.34089475e+00]\n",
      " [1.13216592e+00]\n",
      " [1.65351126e+01]\n",
      " [1.51858010e+01]\n",
      " [1.70260331e+01]\n",
      " [1.13887743e-04]\n",
      " [1.05997007e+01]\n",
      " [1.55159194e+01]\n",
      " [1.16021265e+01]\n",
      " [1.88702509e+01]\n",
      " [8.39064302e+00]\n",
      " [8.19250112e+00]\n",
      " [4.05388653e+00]\n",
      " [2.79030641e+00]\n",
      " [4.26498661e+00]\n",
      " [1.53629506e+01]\n",
      " [6.85666826e+00]\n",
      " [1.35148226e+01]\n",
      " [2.58209500e+00]\n",
      " [1.29444269e+01]\n",
      " [1.75853038e+01]\n",
      " [1.09572039e+01]\n",
      " [1.02479461e+01]\n",
      " [1.62690481e+01]\n",
      " [1.67122559e+00]\n",
      " [2.65224940e+00]\n",
      " [1.96487379e+01]\n",
      " [3.42482164e+00]\n",
      " [1.90657529e+01]\n",
      " [1.12029288e+01]\n",
      " [6.59080629e+00]\n",
      " [4.53887392e+00]\n",
      " [2.59773661e+00]\n",
      " [1.85580360e+01]\n",
      " [1.73606953e+01]\n",
      " [9.27576804e+00]\n",
      " [1.53261400e+01]\n",
      " [6.73463451e-03]\n",
      " [1.35669301e+01]\n",
      " [5.82709104e+00]\n",
      " [1.82167949e+01]\n",
      " [1.83673130e+00]\n",
      " [3.62595287e+00]\n",
      " [6.23901137e+00]\n",
      " [7.85714434e+00]\n",
      " [4.85748549e-01]\n",
      " [1.69348769e+01]\n",
      " [9.29300958e-10]\n",
      " [5.65043685e+00]\n",
      " [1.71620379e+00]\n",
      " [1.49774930e+01]\n",
      " [8.30433050e-01]\n",
      " [1.64496759e+01]\n",
      " [1.86972542e+01]\n",
      " [1.78431212e+01]\n",
      " [2.24781880e+00]\n",
      " [6.07867105e-01]\n",
      " [6.33471891e-01]\n",
      " [3.41698669e+00]\n",
      " [4.13908763e+00]\n",
      " [1.19216618e+01]\n",
      " [4.13434831e-03]\n",
      " [1.70781246e+01]\n",
      " [1.94807334e-01]\n",
      " [4.60016816e+00]\n",
      " [1.73053605e+01]\n",
      " [1.06696364e+01]\n",
      " [1.18759159e+01]\n",
      " [1.46381716e+01]\n",
      " [4.89649006e+00]\n",
      " [1.97755266e-03]\n",
      " [1.78640257e+00]\n",
      " [9.54644671e+00]\n",
      " [2.18713954e-01]\n",
      " [1.54215874e-02]\n",
      " [1.38152843e+01]\n",
      " [1.35241831e+00]\n",
      " [1.13273993e+01]\n",
      " [3.84871938e+00]\n",
      " [5.60392160e+00]\n",
      " [7.21264643e+00]\n",
      " [4.39214079e+00]\n",
      " [2.87288961e+00]\n",
      " [1.59786668e+00]\n",
      " [1.04691840e+01]\n",
      " [3.58654044e-01]\n",
      " [1.69948161e+01]\n",
      " [3.98431981e+00]\n",
      " [1.09999608e+01]\n",
      " [5.87418498e-01]\n",
      " [4.90226991e+00]\n",
      " [5.83159148e+00]\n",
      " [6.66483056e+00]\n",
      " [6.02440479e+00]\n",
      " [1.29132447e+00]\n",
      " [1.44344141e+01]\n",
      " [4.11757579e+00]\n",
      " [5.58340464e-01]\n",
      " [1.29802938e+01]\n",
      " [1.59304927e+01]\n",
      " [9.52932466e+00]\n",
      " [4.22027232e+00]\n",
      " [3.00549044e+00]\n",
      " [6.23352160e+00]\n",
      " [6.92439064e+00]\n",
      " [9.49434880e+00]\n",
      " [2.54602654e+00]\n",
      " [1.64428399e+01]\n",
      " [3.32097113e-06]\n",
      " [1.03165267e+01]\n",
      " [2.97044106e-01]\n",
      " [7.98417586e+00]\n",
      " [3.11951809e+00]\n",
      " [1.17697302e+01]\n",
      " [8.82010025e+00]\n",
      " [3.78356317e-01]\n",
      " [1.22756786e+01]\n",
      " [6.68733015e-01]\n",
      " [1.71405856e+00]\n",
      " [1.25014548e+01]\n",
      " [3.43689685e+00]\n",
      " [4.83799291e-01]\n",
      " [7.93567336e+00]\n",
      " [1.37999497e+01]\n",
      " [1.97982953e+01]\n",
      " [1.03399127e+01]\n",
      " [1.11421950e+00]\n",
      " [1.42702743e+01]\n",
      " [2.50401837e-01]\n",
      " [1.65426873e+01]\n",
      " [4.56269976e-02]\n",
      " [1.92344793e+01]\n",
      " [1.91588254e-01]\n",
      " [8.96670160e+00]\n",
      " [1.03866889e+00]\n",
      " [5.22918657e+00]\n",
      " [5.49045969e+00]\n",
      " [1.03735779e+00]\n",
      " [5.75525660e+00]\n",
      " [5.79808917e+00]\n",
      " [1.46953267e+01]\n",
      " [1.42007173e+01]\n",
      " [1.61172801e+00]\n",
      " [2.68990104e+00]\n",
      " [1.31654205e+01]\n",
      " [1.73512319e+01]\n",
      " [7.10978058e+00]\n",
      " [1.32926945e+01]\n",
      " [4.35201157e+00]\n",
      " [8.99391819e+00]\n",
      " [1.63105414e+01]\n",
      " [8.53404412e+00]\n",
      " [4.53737258e+00]\n",
      " [1.75027927e+01]\n",
      " [2.38212306e+00]\n",
      " [1.07888925e+01]\n",
      " [1.33131676e+01]\n",
      " [1.47868115e+01]\n",
      " [3.51485049e+00]\n",
      " [3.83508821e+00]\n",
      " [1.11451705e+01]\n",
      " [7.73532280e+00]\n",
      " [1.12227702e+01]\n",
      " [8.01739991e+00]\n",
      " [1.22965622e+01]\n",
      " [7.44710107e-07]\n",
      " [3.43713119e+00]\n",
      " [1.18116465e+01]\n",
      " [1.47074423e+01]\n",
      " [5.45654587e-01]\n",
      " [1.36596629e+01]\n",
      " [2.63186632e-03]\n",
      " [5.16949487e-01]\n",
      " [1.36879570e+01]\n",
      " [6.22581297e-04]\n",
      " [1.44289511e+01]\n",
      " [2.65227291e+00]\n",
      " [4.12562949e+00]\n",
      " [9.15081441e+00]\n",
      " [1.79179830e+00]\n",
      " [2.72256268e+00]\n",
      " [8.94888845e+00]\n",
      " [1.99501008e+01]\n",
      " [1.82890979e+01]\n",
      " [3.02704368e+00]\n",
      " [1.97319357e+01]\n",
      " [4.52284255e+00]\n",
      " [1.74403626e+01]\n",
      " [4.17756561e+00]\n",
      " [8.20761780e-01]\n",
      " [1.25680445e+00]\n",
      " [1.51277328e+01]\n",
      " [8.31005800e+00]\n",
      " [9.72428525e+00]\n",
      " [1.72463310e+01]\n",
      " [2.39295438e+00]\n",
      " [4.42292418e+00]\n",
      " [1.27397970e+01]\n",
      " [8.73422417e+00]\n",
      " [3.44090552e+00]\n",
      " [9.60209778e+00]\n",
      " [6.76734245e+00]\n",
      " [8.13336457e+00]\n",
      " [3.55362948e+00]\n",
      " [1.10414334e+01]\n",
      " [1.52929839e+01]\n",
      " [1.78090702e+01]\n",
      " [1.67946303e+00]\n",
      " [7.47718720e+00]\n",
      " [1.29291083e+01]\n",
      " [1.32791632e+00]\n",
      " [1.07986784e+01]\n",
      " [1.02302783e+00]\n",
      " [3.62824195e-01]\n",
      " [1.07556768e+01]\n",
      " [4.71488233e+00]\n",
      " [9.64903840e+00]\n",
      " [1.94878977e+01]\n",
      " [1.35946562e+01]\n",
      " [1.95599372e+01]\n",
      " [1.64046069e+00]\n",
      " [1.57877835e+01]\n",
      " [1.04858659e+00]\n",
      " [7.71732175e+00]\n",
      " [3.61567965e+00]\n",
      " [1.86335908e+01]\n",
      " [1.14608992e+01]\n",
      " [1.22841358e+01]\n",
      " [2.00841619e-01]\n",
      " [3.32358414e-01]\n",
      " [1.82029412e+01]\n",
      " [1.30610469e+01]\n",
      " [7.96222501e+00]\n",
      " [1.26518196e+01]\n",
      " [3.01152757e+00]\n",
      " [8.88209616e+00]\n",
      " [1.89390080e+01]\n",
      " [3.40380846e-01]\n",
      " [1.23014964e+01]\n",
      " [4.66710838e+00]\n",
      " [6.21786089e+00]\n",
      " [5.86431797e+00]\n",
      " [9.52770364e+00]\n",
      " [1.65247696e+01]\n",
      " [4.17357598e+00]\n",
      " [7.24294501e+00]\n",
      " [7.56721230e+00]\n",
      " [2.33031668e+00]\n",
      " [1.31567307e+01]\n",
      " [1.53151580e+00]\n",
      " [2.49979353e+00]\n",
      " [7.65900460e-01]\n",
      " [6.75332070e+00]\n",
      " [4.37578058e-03]\n",
      " [4.24355701e+00]\n",
      " [6.25117411e+00]\n",
      " [1.36325654e-04]\n",
      " [6.87244411e+00]\n",
      " [3.68684437e-01]\n",
      " [7.02968327e+00]\n",
      " [5.05311978e+00]\n",
      " [1.99736671e+00]\n",
      " [1.26247042e+01]\n",
      " [1.80480793e+01]\n",
      " [5.26599046e+00]\n",
      " [2.85014784e+00]\n",
      " [2.23798571e-02]\n",
      " [2.60387840e-01]\n",
      " [1.51801356e+00]\n",
      " [8.75944151e-01]\n",
      " [1.26814091e-03]\n",
      " [6.41974645e+00]\n",
      " [9.93626695e+00]\n",
      " [2.98683778e+00]\n",
      " [4.21912301e+00]\n",
      " [1.72054331e+01]\n",
      " [3.50396836e+00]\n",
      " [2.66494093e-05]\n",
      " [8.92706812e-03]\n",
      " [1.73123141e+00]\n",
      " [1.25296638e+01]\n",
      " [4.67208732e+00]\n",
      " [5.12803398e+00]\n",
      " [2.91732605e-01]\n",
      " [1.60768499e+01]\n",
      " [1.86758583e+01]\n",
      " [5.57222875e-01]\n",
      " [1.01952226e+01]\n",
      " [1.42768676e+01]\n",
      " [4.12963187e+00]\n",
      " [6.22061291e+00]\n",
      " [3.01091901e+00]\n",
      " [1.21303073e+01]\n",
      " [1.49489875e+01]\n",
      " [1.78709755e+01]\n",
      " [9.61977997e+00]\n",
      " [1.06312192e+01]\n",
      " [1.74097183e+01]\n",
      " [5.21496183e-01]\n",
      " [1.09558836e+01]\n",
      " [2.80481699e-01]\n",
      " [5.00741319e+00]\n",
      " [1.53744054e-01]\n",
      " [4.80126558e+00]\n",
      " [1.74015277e+01]\n",
      " [1.45054882e+00]\n",
      " [4.65798143e+00]\n",
      " [9.45231315e+00]\n",
      " [1.83178366e+01]\n",
      " [4.83058763e+00]\n",
      " [1.39397871e+01]\n",
      " [3.40370635e-01]\n",
      " [3.95797201e+00]\n",
      " [1.78570348e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Create lists to store predictions and true labels\n",
    "preds = []\n",
    "targets = []\n",
    "\n",
    "# Predict on the test set and store predictions and true labels\n",
    "for inputs, labels in train_dataloader:\n",
    "    inputs = inputs.double()\n",
    "    labels = labels.double()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "    # Reshape the target tensor if necessary\n",
    "    if labels.shape != outputs.shape:\n",
    "        labels = labels.view(-1, 1)\n",
    "    preds.extend(outputs.tolist())\n",
    "    targets.extend(labels.tolist())\n",
    "\n",
    "# Convert the predictions and targets to numpy arrays\n",
    "preds = np.array(preds)\n",
    "targets = np.array(targets)\n",
    "\n",
    "# Print the predictions and targets\n",
    "print(\"Predictions: \", preds)\n",
    "print(\"Targets: \", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[147], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m i, (inputs, targets) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m      6\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> 7\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs\u001b[39m.\u001b[39;49mdouble())\n\u001b[1;32m      8\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, targets\u001b[39m.\u001b[39mdouble())\n\u001b[1;32m      9\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[145], line 27\u001b[0m, in \u001b[0;36mMyModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mdouble() \u001b[39m# convert input tensor to double precision\u001b[39;00m\n\u001b[1;32m     26\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m# transpose input tensor to shape (batch_size, num_channels, seq_length)\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m     28\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[1;32m     29\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/nn/modules/conv.py:307\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 307\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/nn/modules/conv.py:303\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    301\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    302\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 303\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    304\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # training loop\n",
    "    for i, (inputs, targets) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # validation loop\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for j, (inputs, targets) in enumerate(train_dataloader):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "        val_loss = total_loss / len(train_dataloader)\n",
    "        \n",
    "    print(f\"Epoch {epoch+1} - Train Loss: {loss.item():.4f} - Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38_PT_TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
